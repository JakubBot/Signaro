import asyncio
import json
from typing import Dict, List

from helpers.app_analysis import monitoring_task
import websockets
from fastapi import FastAPI
from aiortc import (
    RTCPeerConnection,
    RTCSessionDescription,
    MediaStreamTrack,
)
from aiortc.contrib.media import MediaRelay
from helpers.utils import add_ice_candidate_safe
from video_transform_track import VideoTransformTrack,cleanup_global_resources
from config import SIGNALING_URI, WAIT_FOR_TRACK_SECONDS, RECONNECT_DELAY_SECONDS

app = FastAPI()

# Global state
pcs: Dict[str, RTCPeerConnection] = {}  # clientId -> PeerConnection
pending_ice: Dict[str, List[dict]] = {}  # clientId -> list of pending ICE candidates
# Maps clientId -> asyncio.Future used to wait for first remote track
track_waiters: Dict[str, asyncio.Future] = {}

async def send_ice_candidate(ws, client_id: str, candidate_dict):
    """Send ICE candidate to Spring WebSocket."""
    try:
        out = {"type": "ice", "to": client_id, "candidate": candidate_dict}
        await ws.send(json.dumps(out))
        print(f"[{client_id}] üì§ ICE candidate sent: {candidate_dict}")
    except Exception as e:
        print(f"[{client_id}] ‚ùå Failed to send ICE candidate: {e}")


async def handle_offer(ws, msg):
    """
    Handle incoming 'offer' message forwarded by Spring.
    Expect msg to include 'from' (clientId) and 'sdp' (object or string).
    """
    client_id = msg.get("from")
    if not client_id:
        print("offer without 'from' -> ignoring")
        return

    # Clean up existing pc for client if present
    if client_id in pcs:
        old_pc = pcs[client_id]
        await closeTracks(old_pc, client_id)

        pcs.pop(client_id, None)
        track_waiters.pop(client_id, None)
        pending_ice.pop(client_id, None)

    pc = RTCPeerConnection()
    pcs[client_id] = pc

    # Future to wait for first remote track (so we can add relay-subscription as local track)
    loop = asyncio.get_running_loop()
    waiter: asyncio.Future = loop.create_future()
    track_waiters[client_id] = waiter

    @pc.on("icecandidate")
    def on_icecandidate(candidate):  # ‚úÖ sync function
        """Handle local ICE candidates generated by aiortc."""
        print(f"[{client_id}] üßä Local ICE candidate generated: {candidate}")

        if candidate is None:
            # End of candidates
            print(f"[{client_id}] üèÅ ICE gathering complete")
            asyncio.create_task(send_ice_candidate(ws, client_id, None))
        else:
            # Send candidate to Spring
            candidate_dict = {
                "candidate": str(candidate),
                "sdpMid": candidate.sdpMid,
                "sdpMLineIndex": candidate.sdpMLineIndex,
            }
            asyncio.create_task(send_ice_candidate(ws, client_id, candidate_dict))

    @pc.on("track")
    def on_track(track: MediaStreamTrack):
        # fulfill waiter with the first remote track
        print(f"[{client_id}] remote track received: kind={track.kind}")
        w = track_waiters.get(client_id)
        if w and not w.done():
            w.set_result(track)
        # optional: spawn background task to read frames
        # asyncio.create_task(read_frames(client_id, track))

    # parse sdp
    sdp_obj = msg.get("sdp")
    if isinstance(sdp_obj, dict):
        sdp_type = sdp_obj.get("type", "offer")
        sdp_text = sdp_obj.get("sdp")
    else:
        sdp_type = msg.get("type", "offer")
        sdp_text = sdp_obj

    offer = RTCSessionDescription(sdp=sdp_text, type=sdp_type)
    await pc.setRemoteDescription(offer)

    # Wait for incoming track a short time so we can echo it back
    track = None
    try:
        track = await asyncio.wait_for(waiter, timeout=WAIT_FOR_TRACK_SECONDS)
    except asyncio.TimeoutError:
        # no remote track arrived in time -> proceed without echo
        print(
            f"[{client_id}] timeout waiting for remote track, will answer without echo"
        )

    if track:
        try:
            # here can make manipulation on the track
            processed_track = VideoTransformTrack(track)
            pc.addTrack(processed_track)
            # used when no modification is needed
            # relay = MediaRelay()
            # relayed = relay.subscribe(track)
            # pc.addTrack(relayed)
            print(f"[{client_id}] added relayed local track (echo)")
        except Exception as e:
            print(f"[{client_id}] error adding relayed track: {e}")
            # traceback.print_exc()

    # Flush any pending ICE candidates
    pending = pending_ice.pop(client_id, [])
    for cand_dict in pending:
        try:
            await add_ice_candidate_safe(pc, client_id, cand_dict)
        except Exception as e:
            print(f"[{client_id}] addIceCandidate (pending) failed: {e}")

    # create and send answer
    answer = await pc.createAnswer()
    await pc.setLocalDescription(answer)

    out = {
        "type": "answer",
        "to": client_id,
        "sdp": {"type": pc.localDescription.type, "sdp": pc.localDescription.sdp},
    }
    await ws.send(json.dumps(out))
    print(f"[{client_id}] answer sent")


async def handle_ice(msg):
    """Handle incoming ICE candidate from JS client."""
    client_id = msg.get("from")
    cand_dict = msg.get("candidate")

    if not client_id:
        print("‚ùå ICE message without 'from', ignoring")
        return

    if not cand_dict:
        print(f"[{client_id}] üèÅ Received end-of-candidates signal")
        return

    # print(f"[{client_id}] üßä Received ICE candidate: {cand_dict}")

    pc = pcs.get(client_id)
    if not pc:
        print(f"[{client_id}] ‚ùå No peer connection found, buffering candidate")
        pending_ice.setdefault(client_id, []).append(cand_dict)
        return

    if pc.remoteDescription and pc.remoteDescription.type:
        await add_ice_candidate_safe(pc, client_id, cand_dict)
    else:
        print(f"[{client_id}] üì¶ Buffering ICE candidate (no remote description)")
        pending_ice.setdefault(client_id, []).append(cand_dict)


async def handle_close(msg):
    """
    Handle close request from Spring.
    Expect msg: { "type": "close", "from": "<clientId>" }
    """
    client_id = msg.get("from")
    if not client_id:
        return

    pc = pcs.pop(client_id, None)
    await closeTracks(pc, client_id)

    pending_ice.pop(client_id, None)
    track_waiters.pop(client_id, None)
    print(f"[{client_id}] cleaned up")


async def closeTracks(pc, client_id):
    if pc:
        # stop all tracks
        for sender in pc.getSenders():
            track = sender.track
            print(f"[{client_id}] üîç Track debug:")
            print(f"  - track: {track}")
            print(f"  - type: {type(track)}")
            print(f"  - class name: {track.__class__.__name__}")
            print(f"  - module: {track.__class__.__module__}")
            print(
                f"  - isinstance VideoTransformTrack: {isinstance(track, VideoTransformTrack)}"
            )
            print(f"  - VideoTransformTrack class: {VideoTransformTrack}")
            if isinstance(track, VideoTransformTrack):
                try:
                    print("before closing track")
                    await track._stopVideoTransformTrack()  # <- stops executor and tasks
                    print("after closing track")
                except Exception as e:
                    print(f"[{client_id}] error stopping track: {e}")
        try:
            await pc.close()
        except Exception as e:
            print(f"[{client_id}] error closing pc: {e}")


# add to spring boot on websocket send event to close !!!
async def signaling_client_loop():
    """
    Connect to Spring WebSocket and respond to messages forwarded from JS clients.
    Reconnects on error with a delay.
    """
    while True:
        try:
            async with websockets.connect(SIGNALING_URI) as ws:
                print("Connected to signaling:", SIGNALING_URI)
                async for message in ws:
                    try:
                        msg = json.loads(message)
                    except Exception:
                        print("Received non-JSON message:", message)
                        continue

                    mtype = msg.get("type")

                    if mtype == "offer":
                        await handle_offer(ws, msg)
                    elif mtype == "ice":
                        await handle_ice(msg)
                    elif mtype == "close":
                        await handle_close(msg)
                    else:
                        print("Unknown message type:", mtype, "payload:", msg)
        except Exception as e:
            print("Signaling connection error:", e)
            print("Reconnecting in", RECONNECT_DELAY_SECONDS, "s...")
            await asyncio.sleep(RECONNECT_DELAY_SECONDS)


# async def monitor_connections():
#     """Monitor active peer connections continuously."""
#     while True:
#         print(f"\n{'='*50}")
#         print(f"üìä SYSTEM MONITOR")
#         print(f"{'='*50}")

#         # Global track stats
#         VideoTransformTrack.print_global_stats()

#         # Connection stats
#         print(f"\nüîó CONNECTIONS: {len(pcs)}")
#         for client_id, pc in pcs.items():
#             print(f"  [{client_id}] State: {pc.connectionState}")

#         # Memory stats
#         try:
#             memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
#             print(f"\nüíæ MEMORY: {memory_mb:.1f} MB")
#         except:
#             pass

#         print(f"{'='*50}\n")
#         await asyncio.sleep(5)


@app.on_event("startup")
async def startup_event():
    asyncio.create_task(signaling_client_loop())
    asyncio.create_task(monitoring_task())  # Add monitoring task


# @app.on_event("shutdown")
# async def shutdown_event():
    # CLEANUP GLOBAL RESOURCES
    # cleanup_global_resources()

@app.get("/")
async def check_status():
    return "Working"


@app.post("/generateFromText")
async def generate_from_text(payload: dict):
    return "To do"
